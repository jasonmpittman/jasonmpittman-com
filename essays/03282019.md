# What is an Agent
## Jason M. Pittman
## March 28th, 2019

The goal with this work is to provide my view on the fundamental mechanisms underlying the field of artificial intelligence. I am going to explain, in simple terms accompanied by simple math and simple programming examples, the theory and practical application of AI. With that said, we should start at the beginning and address the concept of an *agent*.

### What is an agent?

Artificial intelligence has become in vogue technology over the last few years. Between [self-driving cars](https://www.tesla.com) and a plethora of commercials (see [Microsoft](https://www.youtube.com/watch?v=9tucY7Jhhs4)), along with the travel mapping, predictive marketing, and scheduling apps in the middle, modern society has pushed all-in on artificial intelligence. I don't know many baby boomers are necessarily aware of Twitch.tv as the premiere streaming platform but I would wager a tidy sum on the same demographic having at least a partially correct working definition for AI. Unfortunately, I have the impression that people believe AI is something that it can never be.

Here's what AI is not: true thinking, conscious machines. That's easy and leaves us to work on the hard stuff.

If you've read my synthetic intelligence essays at all, you'll be familiar with my concept of intelligence. Well, AI implements the same idea. However, with AI the instantiation of intelligence is (a) intended to imitate human intelligence and (b) occurs through an *agent*. Now, intelligence in this context is wholly bound to the concept of *thinking*. Thus, we can conceptualize an agent to be the conceptual and logical manifestation of intelligence through thinking.

Okay, so an agent is us in software form, loosely speaking. Thinking is not enough though. We, as humans, don't just think after all. We also act on or as a result of our thinking. This helps further define the agent because the fundamental reason agents exist is to act.

A natural question at this point would be something like, "what is *acting*?" or "act in what manner?". Great.

### Thinking and acting

We can define types of agents by the way in which the agent *thinks* but more so in how the agent *acts*. I'll tackle the specific types of agents in the future. For now, let's agree we want agents to think and act rationally. In other words, we wish our AI to think and act such that it reaches a correct resolution. Make sense, right?

Let's take a lumberjack AI for example.

The problem is that cutting down trees is dangerous to humans. Furthermore, cutting down trees is labor intensive and not terribly efficient. Thus, we want an AI to think about which trees to harvest and act towards harvesting those trees. Because the goal of cutting trees is to create lumber, we define *correct* in this scenario as the production of 100 pieces of lumber a minute. Accordingly, our lumberjack agent thinks about which trees to harvest, how to cut each tree into optimal segments and act in a manner consistent with such thinking so that it produces 100 pieces of lumber every minute.

### The other half

An important concept in AI is that agents are only half of the equation. In fact, although the majority of popular focus is on the thinking and acting program, operationally the agent is not an important component. The agent is actually the least trustworthy, least meaningful part. Think about our lumberjack AI and where it might go wrong. Next time we'll talk about *environments* and connect our knowledge of agents to environments using the lumberjack example. Then, we'll begin to understand how AI is used to solve problems.